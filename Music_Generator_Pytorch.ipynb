{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Generator_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfazZRmp3pVR"
      },
      "source": [
        "# Music Generation\r\n",
        "\r\n",
        "<img src=https://media.giphy.com/media/xT8qBp0R5SxfLMIgjC/giphy.gif>\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t399rWdU0kqB"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import numpy as np\r\n",
        "import torch.nn.functional as F\r\n",
        "import editdistance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmUmxbf_l_af"
      },
      "source": [
        "# Remove index,title, source\r\n",
        "with open('Data_Tunes.txt') as f:\r\n",
        "    with open ('Cleaned_tunes.txt','w') as f_clean:\r\n",
        "        for line in f:\r\n",
        "            if line[:2] not in [\"X:\",\"T:\",'% ','S:']:\r\n",
        "                f_clean.write(line)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4n0A_n38KHY6"
      },
      "source": [
        "# Read file\r\n",
        "filename=\"Cleaned_tunes.txt\"\r\n",
        "with open(filename) as f:\r\n",
        "  abc_file=f.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBswRV0ILvYm"
      },
      "source": [
        "# Define architecture\r\n",
        "class LSTMNetwork(nn.Module):\r\n",
        "\r\n",
        "  def __init__(self,unique_chars,n_layers=2,n_hidden=256,n_embed=100,drop_prob=0.5):\r\n",
        "    super().__init__()\r\n",
        "    self.drop_prob=drop_prob\r\n",
        "    self.n_layers=n_layers\r\n",
        "    self.n_hidden = n_hidden\r\n",
        "    self.n_embed=n_embed\r\n",
        "\r\n",
        "    self.embed=nn.Embedding(unique_chars,n_embed)\r\n",
        "    self.lstm = nn.LSTM(n_embed, n_hidden, n_layers, \r\n",
        "                            dropout=drop_prob, batch_first=True)\r\n",
        "    self.dropout = nn.Dropout(drop_prob)\r\n",
        "    self.fc = nn.Linear(n_hidden, unique_chars)\r\n",
        "  \r\n",
        "  def forward(self, x, hc):\r\n",
        "    ''' Forward pass through the network. The inputs are x, and the hidden/cell state 'hc'. '''\r\n",
        "    x = self.embed(x)\r\n",
        "    x, (h, c) = self.lstm(x, hc)\r\n",
        "    x = self.dropout(x)\r\n",
        "    x = x.view(x.size()[0]*x.size()[1], self.n_hidden)\r\n",
        "    x = self.fc(x)\r\n",
        "    return x, (h, c)\r\n",
        "        \r\n",
        "  def init_hidden(self, n_seqs,cuda=True):\r\n",
        "    ''' Initialize hidden state '''\r\n",
        "    # Create two new tensors with sizes n_layers x n_seqs x n_hidden,\r\n",
        "    # initialized to zero, for hidden state and cell state of LSTM\r\n",
        "    hidden=torch.zeros(self.n_layers, n_seqs, self.n_hidden)\r\n",
        "    cell=torch.zeros(self.n_layers, n_seqs, self.n_hidden)\r\n",
        "\r\n",
        "    if cuda:\r\n",
        "      hidden,cell=hidden.cuda(),cell.cuda()\r\n",
        "    return (hidden,cell)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mH0bVHqVO_9"
      },
      "source": [
        "class MusicGenerator():\r\n",
        "  \r\n",
        "  def __init__(self,abc_file):\r\n",
        "    self.file_data=abc_file\r\n",
        "    self.char_to_index = {ch: i for (i, ch) in enumerate(sorted(list(set(abc_file))))}\r\n",
        "    self.index_to_char = {i: ch for (ch, i) in self.char_to_index.items()}\r\n",
        "    self.data = np.asarray([self.char_to_index[c] for c in abc_file], dtype = np.int32)\r\n",
        "    self.unique_chars=len(self.char_to_index)\r\n",
        "    self.model=LSTMNetwork(unique_chars=self.unique_chars,n_hidden=256, n_layers=2,n_embed=100,drop_prob=0.25)\r\n",
        "\r\n",
        "  \r\n",
        "  def fit(self,epochs=50,n_seqs=16,n_steps=64,lr=0.001,device='GPU',cuda=True,val_frac=0.2,loss_criterion=nn.CrossEntropyLoss()):\r\n",
        "    '''Train the LSTM network'''\r\n",
        "    self.loss_criterion=loss_criterion\r\n",
        "    train_data,val_data=self.train_val_data(val_frac)\r\n",
        "    #Set the model in train mode    \r\n",
        "    self.model.train()\r\n",
        "    opt = torch.optim.Adam(self.model.parameters(), lr=lr)\r\n",
        "    \r\n",
        "    if cuda:\r\n",
        "      self.model.cuda()\r\n",
        "\r\n",
        "    for e in range(epochs):\r\n",
        "      h = self.model.init_hidden(n_seqs,cuda)\r\n",
        "      train_losses=[]\r\n",
        "      for x,y in self.get_batches(train_data,n_seqs,n_steps):\r\n",
        "        \r\n",
        "        inputs,targets = torch.from_numpy(x).type(torch.cuda.LongTensor), torch.from_numpy(y).type(torch.cuda.LongTensor)\r\n",
        "\r\n",
        "        if cuda:\r\n",
        "          inputs,targets = inputs.cuda(),targets.cuda()\r\n",
        "\r\n",
        "               \r\n",
        "        h = tuple([each.data for each in h])\r\n",
        "        #set all gradients to zero\r\n",
        "        self.model.zero_grad()\r\n",
        "\r\n",
        "        output,h=self.model.forward(inputs,h)\r\n",
        "\r\n",
        "        # Calculate the forward losses\r\n",
        "        loss = self.loss_criterion(output, targets.view(n_seqs*n_steps).type(torch.cuda.LongTensor))\r\n",
        "        train_losses.append(loss.item())\r\n",
        "        #backpropagate\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        opt.step()\r\n",
        "\r\n",
        "      val_losses=self.epoch_validation_loss(val_data,n_seqs,n_steps,cuda)\r\n",
        "      self.print_epoch_loss(e,epochs,train_losses,val_losses)\r\n",
        "        \r\n",
        "  def train_val_data(self,val_frac):\r\n",
        "    '''Split the data into a train and validation set'''\r\n",
        "    val_idx = int(len(self.data)*(1-val_frac))\r\n",
        "    train_data, val_data = self.data[:val_idx], self.data[val_idx:]\r\n",
        "    return(train_data,val_data)\r\n",
        "  \r\n",
        "  def epoch_validation_loss(self,val_data,n_seqs,n_steps,cuda=False):\r\n",
        "      '''Calculate validation loss at the end of each epoch'''\r\n",
        "      val_h = self.model.init_hidden(n_seqs)\r\n",
        "      val_losses = []\r\n",
        "      \r\n",
        "      for x, y in self.get_batches(val_data, n_seqs, n_steps):\r\n",
        "          \r\n",
        "          x, y = torch.from_numpy(x).type(torch.cuda.LongTensor), torch.from_numpy(y).type(torch.cuda.LongTensor)\r\n",
        "          val_h = tuple([each.data for each in val_h])\r\n",
        "          \r\n",
        "          inputs, targets = x, y\r\n",
        "          if cuda:\r\n",
        "              inputs, targets = inputs.cuda(), targets.cuda()\r\n",
        "\r\n",
        "          output, val_h = self.model.forward(inputs, val_h)\r\n",
        "          val_loss = self.loss_criterion(output, targets.view(n_seqs*n_steps).type(torch.cuda.LongTensor))\r\n",
        "      \r\n",
        "          val_losses.append(val_loss.item())\r\n",
        "      return val_losses\r\n",
        "\r\n",
        "  def print_epoch_loss(self,e,epochs,train_losses,val_losses):\r\n",
        "    '''Print average train and validation loss at the end of each epoch'''\r\n",
        "    print(\"Epoch: {}/{}...\".format(e+1, epochs),\r\n",
        "                \"Loss: {:.4f}...\".format(np.mean(train_losses)),\r\n",
        "                \"Val Loss: {:.4f}\".format(np.mean(val_losses)))\r\n",
        "\r\n",
        "  \r\n",
        "  def get_batches(self,data, n_seqs, n_steps):\r\n",
        "    '''Generator to create batches of data'''\r\n",
        "    batch_size = n_seqs * n_steps\r\n",
        "    n_batches = len(data)//batch_size\r\n",
        "    data = data[:n_batches * batch_size]\r\n",
        "    data = data.reshape((n_seqs, -1))\r\n",
        "    for n in range(0, data.shape[1], n_steps):\r\n",
        "        x = data[:, n:n+n_steps]\r\n",
        "        y = np.zeros_like(x)\r\n",
        "        try:\r\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], data[:, n+n_steps]\r\n",
        "        except IndexError:\r\n",
        "            y[:, :-1], y[:, -1] = x[:, 1:], data[:, 0]\r\n",
        "        yield x, y\r\n",
        "\r\n",
        "  def predict_next_char(self, char, h=None, cuda=False, top_k=None,t=0.1):\r\n",
        "    '''Predicts next character when generating a sequence'''\r\n",
        "    if cuda:\r\n",
        "        self.model.cuda()\r\n",
        "    else:\r\n",
        "        self.model.cpu()\r\n",
        "    \r\n",
        "    if h is None:\r\n",
        "        h = self.model.init_hidden(1)\r\n",
        "    \r\n",
        "    x = np.array([[self.char_to_index[char]]])\r\n",
        "    inputs = torch.from_numpy(x).type(torch.cuda.LongTensor)\r\n",
        "    \r\n",
        "    if cuda:\r\n",
        "        inputs = inputs.cuda()\r\n",
        "    \r\n",
        "    h = tuple([each.data for each in h])\r\n",
        "    out, h = self.model.forward(inputs, h)\r\n",
        "\r\n",
        "    p = F.softmax(out/t, dim=1).data\r\n",
        "    \r\n",
        "    if cuda:\r\n",
        "        p = p.cpu()\r\n",
        "    \r\n",
        "    if top_k is None:\r\n",
        "        top_ch = np.arange(self.unique_chars)\r\n",
        "    else:\r\n",
        "        p, top_ch = p.topk(top_k)\r\n",
        "        top_ch = top_ch.numpy().squeeze()\r\n",
        "    \r\n",
        "    p = p.numpy().squeeze()\r\n",
        "        \r\n",
        "    char = np.random.choice(top_ch, p=p/p.sum())\r\n",
        "        \r\n",
        "    return self.index_to_char[char], h\r\n",
        "  \r\n",
        "  def generate_music(self,max_len=200, prime='A', top_k=None, t=0.1,cuda=False,export_to_file=True,file_name='music.abc.txt'): \r\n",
        "    '''Generate a new music snippet'''\r\n",
        "    if cuda:\r\n",
        "        self.model.cuda()\r\n",
        "    else:\r\n",
        "        self.model.cpu()\r\n",
        "\r\n",
        "    self.model.eval()\r\n",
        "    \r\n",
        "    chars = [ch for ch in prime]\r\n",
        "    h = self.model.init_hidden(1)\r\n",
        "    \r\n",
        "    for ch in prime:\r\n",
        "        char, h = self.predict_next_char(ch, h, cuda=cuda, top_k=top_k,t=t)\r\n",
        "\r\n",
        "    chars.append(char)\r\n",
        "    prev_char=chars[-1]\r\n",
        "    \r\n",
        "    for ii in range(max_len):\r\n",
        "        char, h = self.predict_next_char(chars[-1], h, cuda=cuda, top_k=top_k)\r\n",
        "        if (char=='\\n')&(prev_char=='\\n'):\r\n",
        "          break\r\n",
        "        prev_char=char\r\n",
        "        chars.append(char)\r\n",
        "    music = ''.join(chars)\r\n",
        "    \r\n",
        "    if export_to_file:\r\n",
        "      with open(file_name, 'w') as file: \r\n",
        "        file.write(music)\r\n",
        "      print(f\"File written: {file_name}\\n\")\r\n",
        "    \r\n",
        "    print(f'Music generated:\\n\\n{music}')\r\n",
        "    self.edit_distance(music)\r\n",
        "\r\n",
        "  def edit_distance(self,music):\r\n",
        "    '''Calculate Levenshtein distance for the new music generated'''\r\n",
        "    songs=self.file_data.split('\\n\\n\\n')\r\n",
        "    song_distances,song_length = [],[]\r\n",
        "    \r\n",
        "    for song in songs:\r\n",
        "      song_distances.append(editdistance.eval(song,music))\r\n",
        "      song_length.append(len(song))\r\n",
        "  \r\n",
        "    print(f'\\nMean length of input songs: {int(np.mean(song_length))}')\r\n",
        "    print(f'Output song length: {len(music)}')\r\n",
        "    print(f'Min Levenshtein distance: {np.min(song_distances)}')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtL1wSMNqPQf"
      },
      "source": [
        "generator=MusicGenerator(abc_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkcBkLz0qyDz",
        "outputId": "a00a41fd-214f-4798-8d35-11eb9b9b9b54"
      },
      "source": [
        "print(\"Model Architecture\\n\")\r\n",
        "generator.model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Architecture\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMNetwork(\n",
              "  (embed): Embedding(74, 100)\n",
              "  (lstm): LSTM(100, 256, num_layers=2, batch_first=True, dropout=0.25)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              "  (fc): Linear(in_features=256, out_features=74, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev4xSFUDq4sO",
        "outputId": "1ad422fe-ddda-446b-8886-7e2d46653c8d"
      },
      "source": [
        "generator.fit(epochs=30,n_seqs=128,n_steps=64,lr=0.001,cuda=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/30... Loss: 3.6861... Val Loss: 3.3431\n",
            "Epoch: 2/30... Loss: 3.0706... Val Loss: 3.2788\n",
            "Epoch: 3/30... Loss: 2.8684... Val Loss: 3.0207\n",
            "Epoch: 4/30... Loss: 2.5584... Val Loss: 2.8023\n",
            "Epoch: 5/30... Loss: 2.2972... Val Loss: 2.6930\n",
            "Epoch: 6/30... Loss: 2.0998... Val Loss: 2.6344\n",
            "Epoch: 7/30... Loss: 1.9593... Val Loss: 2.6184\n",
            "Epoch: 8/30... Loss: 1.8505... Val Loss: 2.5679\n",
            "Epoch: 9/30... Loss: 1.7594... Val Loss: 2.5214\n",
            "Epoch: 10/30... Loss: 1.6813... Val Loss: 2.4740\n",
            "Epoch: 11/30... Loss: 1.6173... Val Loss: 2.4329\n",
            "Epoch: 12/30... Loss: 1.5639... Val Loss: 2.4058\n",
            "Epoch: 13/30... Loss: 1.5189... Val Loss: 2.3761\n",
            "Epoch: 14/30... Loss: 1.4776... Val Loss: 2.3373\n",
            "Epoch: 15/30... Loss: 1.4435... Val Loss: 2.3045\n",
            "Epoch: 16/30... Loss: 1.4170... Val Loss: 2.2749\n",
            "Epoch: 17/30... Loss: 1.3866... Val Loss: 2.2632\n",
            "Epoch: 18/30... Loss: 1.3617... Val Loss: 2.2430\n",
            "Epoch: 19/30... Loss: 1.3405... Val Loss: 2.2055\n",
            "Epoch: 20/30... Loss: 1.3193... Val Loss: 2.2180\n",
            "Epoch: 21/30... Loss: 1.3042... Val Loss: 2.2032\n",
            "Epoch: 22/30... Loss: 1.2888... Val Loss: 2.2036\n",
            "Epoch: 23/30... Loss: 1.2709... Val Loss: 2.2264\n",
            "Epoch: 24/30... Loss: 1.2569... Val Loss: 2.2228\n",
            "Epoch: 25/30... Loss: 1.2433... Val Loss: 2.2364\n",
            "Epoch: 26/30... Loss: 1.2261... Val Loss: 2.2266\n",
            "Epoch: 27/30... Loss: 1.2168... Val Loss: 2.1804\n",
            "Epoch: 28/30... Loss: 1.2016... Val Loss: 2.2141\n",
            "Epoch: 29/30... Loss: 1.1861... Val Loss: 2.1951\n",
            "Epoch: 30/30... Loss: 1.1732... Val Loss: 2.1923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SQqoTI8uRZi",
        "outputId": "c691690b-2235-42bc-e2cf-11715ba9e503"
      },
      "source": [
        "generator.generate_music(max_len=200, prime='M:6/8\\nK:A\\nP:A',t=0.5,top_k=5,cuda=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File written: music.abc.txt\n",
            "\n",
            "Music generated:\n",
            "\n",
            "M:6/8\n",
            "K:A\n",
            "P:A\n",
            "|:A|\"A\"A2A A2A|\"D\"d2f fed|\"A\"c2c cBA|\"D\"d3 d2:|\n",
            "\n",
            "\n",
            "Mean length of input songs: 306\n",
            "Output song length: 62\n",
            "Min Levenshtein distance: 102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVXi45pmjkmP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}